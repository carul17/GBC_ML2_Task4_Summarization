{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "## This notebook outlines the concepts behind Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "- concept of capturing very important gist of a long piece of text\n",
    "\n",
    "### Types of Summarization\n",
    "- 1. **Extractive Summarization**\n",
    "    - Select sentences from the corpus that best represent the text\n",
    "    - Arrange them to form a summary\n",
    "- 2. **Abstractive Summarization**\n",
    "    - Captures the very important sentences from the text\n",
    "    - Paraphrases them to form a summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization Libraries\n",
    "- Sumy\n",
    "- Gensim\n",
    "- Summa\n",
    "- BERT **\n",
    "    - BART **\n",
    "    - PEGASUS **\n",
    "    - T5 **\n",
    "\n",
    "** Will be seen in DL-1\n",
    "\n",
    "\n",
    "## 1. Sumy :\n",
    "    1. Luhn – Heurestic method\n",
    "    2. Latent Semantic Analysis\n",
    "    4. LexRank – Unsupervised approach inspired by algorithms PageRank and HITS\n",
    "    5. TextRank - Graph-based summarization technique with keyword extractions in from document\n",
    "\n",
    "Documentation Reference [sumy](https://github.com/miso-belica/sumy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Take a piece of text from wiki page and summarize them using Sumy\n",
    "### Steps\n",
    "- Install the necessary libraries\n",
    "- Import the libraries\n",
    "- Scrape the text from a pre-defined webpage\n",
    "- Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#! pip install sumy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries\n",
    "- HtmlParser\n",
    "- Tokenizer\n",
    "- TextRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "LANGUAGE = \"english\"\n",
    "SENTENCES_COUNT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Automatic_summarization\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parser\n",
    "parser = HtmlParser.from_url(url, Tokenizer(LANGUAGE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize - TextRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summarizer\n",
    "stemmer = Stemmer(LANGUAGE)\n",
    "summarizer = TextRankSummarizer(stemmer)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize\n",
    "summary = summarizer(parser.document, SENTENCES_COUNT)\n",
    "print(\"TextRank Summary:\")\n",
    "for sentence in summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different Summarizers\n",
    "- LexRankSummarizer\n",
    "- LuhnSummarizer\n",
    "- LsaSummarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the summarizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer \n",
    "from sumy.summarizers.luhn import LuhnSummarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Summarizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the summarizers\n",
    "lsa_summarizer = LsaSummarizer(stemmer)\n",
    "lsa_summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "lexrank_summarizer = LexRankSummarizer(stemmer)\n",
    "lexrank_summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "luhn_summarizer = LuhnSummarizer(stemmer)\n",
    "luhn_summarizer.stop_words = get_stop_words(LANGUAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LexRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize using LexRank\n",
    "lexrank_summary = lexrank_summarizer(parser.document, SENTENCES_COUNT)\n",
    "print(\"LexRank Summary:\")\n",
    "for sentence in lexrank_summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LuhnSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize using Luhn\n",
    "luhn_summary = luhn_summarizer(parser.document, SENTENCES_COUNT)\n",
    "print(\"Luhn Summary:\")\n",
    "for sentence in luhn_summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LsaSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize using LSA\n",
    "lsa_summary = lsa_summarizer(parser.document, SENTENCES_COUNT)\n",
    "print(\"LSA Summary:\")\n",
    "for sentence in lsa_summary:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Take a piece of text from wiki page and summarize them using Gensim\n",
    "### Steps\n",
    "- Install the necessary libraries\n",
    "- Import the libraries\n",
    "- Scrape the text from a pre-defined webpage\n",
    "- Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"numpy<=1.16.1\" \"gensim==3.8.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.summarization'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msummarization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m summarize\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'gensim.summarization'"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the text\n",
    "- Use beautifulSoup to extract text (from Task1 of ML-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    \n",
    "    \n",
    "    # Get the webpage content\n",
    "    page = requests.get(url)\n",
    "    \n",
    "    # Create BeautifulSoup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_text(soup):\n",
    "    # Find all paragraph tags\n",
    "    paragraphs = soup.find_all('p')\n",
    "    \n",
    "    # Extract text from paragraphs\n",
    "    text = ' '.join([p.get_text() for p in paragraphs])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Automatic_summarization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = collect_text(get_page(url))\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize\n",
    "- **word_count**: maximum amount of words we want in the summary\n",
    "- **ratio**: fraction of sentences in the original text should be returned as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize using Gensim\n",
    "summary = summarize(text, ratio=0.3)\n",
    "print(\"Gensim Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Take a piece of text from wiki page and summarize them using Summa\n",
    "### Steps\n",
    "- Install the necessary libraries\n",
    "- Import the libraries\n",
    "- Scrape the text from a pre-defined webpage\n",
    "- Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install summa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa import summarizer as summa_summarizer\n",
    "from summa import keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the text\n",
    "- Use beautifulSoup to extract text (from Task1 of ML-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize using Summa\n",
    "summary = summa_summarizer.summarize(text, ratio=0.3)\n",
    "print(\"Summa Summary:\")\n",
    "print(summary)\n",
    "\n",
    "# Extract keywords\n",
    "key_words = keywords.keywords(text)\n",
    "print(\"\\nKeywords:\")\n",
    "print(key_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASSIGNMENT: Take the same medium article (the one I wrote) we used for Task 1 of ML-1 and extract the text and summarize them using all the above methods and provide the best summary with a note saying why the chosen library is the best\n",
    "url = https://medium.com/@subashgandyer/papa-what-is-a-neural-network-c5e5cc427c7\n",
    "\n",
    "### Submit 2 files\n",
    "- (notebook) .ipynb\n",
    "- (summary) .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
